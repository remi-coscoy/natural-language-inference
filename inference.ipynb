{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the trained model\n",
    "\n",
    "## Natural Language Inferencing (NLI): \n",
    "\n",
    "(NLI) is a classical NLP (Natural Language Processing) problem that involves taking two sentences (the premise and the hypothesis ), and deciding how they are related (if the premise *entails* the hypothesis, *contradicts* it, or *neither*).\n",
    "\n",
    "Ex: \n",
    "\n",
    "| Premise | Label | Hypothesis |\n",
    "| --- | --- | --- |\n",
    "| A man inspects the uniform of a figure in some East Asian country. | contradiction | The man is sleeping. |\n",
    "| An older and younger man smiling. | neutral | Two men are smiling and laughing at the cats playing on the floor. |\n",
    "| A soccer game with multiple males playing. | entailment | Some men are playing a sport. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up environment (if not done already)\n",
    "%pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports and functions\n",
    "\n",
    "from transformers import (\n",
    "    AlbertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AlbertTokenizer,\n",
    ")\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import wandb\n",
    "import yaml\n",
    "\n",
    "\n",
    "CONFIG_PATH = \"./config_sample.yaml\"\n",
    "\n",
    "# Load YAML file\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "def load_model(model_checkpoint:str)->torch.nn:\n",
    "    \"\"\" Load a trained model from a checkpoint and prepares it for evaluation. \"\"\"\n",
    "\n",
    "    model = AlbertForSequenceClassification.from_pretrained(\n",
    "            config[\"PRETRAINED_MODEL\"], num_labels=3\n",
    "        )\n",
    "\n",
    "    # Load the last model saved in a checkpoint\n",
    "    checkpoint_path = os.path.join(BEST_MODEL_CHECKPOINT, \"pytorch_model.bin\")\n",
    "    model_state_dict = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    # Prepares for evaluation\n",
    "    model.to(torch.device(\"cuda\"))\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict(premise:str, hypothesis:str, model:torch.nn)->str:\n",
    "    \"\"\" Predict the NLI label for a premise and an hypothesis\"\"\"\n",
    "\n",
    "    tokenizer = AlbertTokenizer.from_pretrained(config[\"PRETRAINED_MODEL\"])\n",
    "\n",
    "    inputs = tokenizer(premise, hypothesis, truncation=True,\n",
    "        padding=\"max_length\", return_tensors=\"pt\"\n",
    "    ).to(torch.device(\"cuda\"))\n",
    "\n",
    "    logits = model(**inputs).logits\n",
    "    \n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    label_mapping= {0:\"ENTAILMENT\", 1: \"NEUTRAL\", 2:\"CONTRADICTION\"}\n",
    "\n",
    "    return label_mapping[predicted_class_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_CHECKPOINT = \"/usr/users/cei2023_2024_sondra_cself/coscoy_rem/Documents/nlp_tp/logs/albert-base-v2_7/checkpoint-90000/\"\n",
    "\n",
    "model = load_model(BEST_MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: An older and younger man smiling.\n",
      "Hypothesis: Two men are smiling and laughing at the cats playing on the floor.\n",
      "Prediction: NEUTRAL\n",
      "\n",
      "Premise: A man inspects the uniform of a figure in some East Asian country\n",
      "Hypothesis: The man is sleeping\n",
      "Prediction: CONTRADICTION\n",
      "\n",
      "Premise: A soccer game with multiple males playing.\n",
      "Hypothesis: Some men are playing a sport\n",
      "Prediction: ENTAILMENT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STANDARD EXAMPLES\n",
    "premises = [\n",
    "    \"An older and younger man smiling.\",\n",
    "    \"A man inspects the uniform of a figure in some East Asian country\",\n",
    "    \"A soccer game with multiple males playing.\"\n",
    "]\n",
    "\n",
    "hypotheses = [\n",
    "    \"Two men are smiling and laughing at the cats playing on the floor.\",\n",
    "    \"The man is sleeping\",\n",
    "    \"Some men are playing a sport\"\n",
    "]\n",
    "\n",
    "for premise, hypothesis in zip(premises, hypotheses):\n",
    "    prediction = predict(premise, hypothesis, model=model)\n",
    "    print(f\"Premise: {premise}\")\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Prediction: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CONTRADICTION'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CUSTOM EXAMPLE\n",
    "PREMISE = \"All animals are pink.\"\n",
    "HYPOTHESIS = \"Socrates is an animal and he is red.\"\n",
    "\n",
    "predict(PREMISE, HYPOTHESIS, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
